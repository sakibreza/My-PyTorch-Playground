{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using_Optimizers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07a84345682a466dbbc8f7debc3feda6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae20146b93cb414296bb9642cab41d00",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cc6a0fcc107484e9af323446755f50a",
              "IPY_MODEL_f5634356c784403faab713da75a91647"
            ]
          }
        },
        "ae20146b93cb414296bb9642cab41d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cc6a0fcc107484e9af323446755f50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5f68ddd1a5fe4c7f86905a8757da8ab3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c0ef20b6009424a96f4c856e943bcd5"
          }
        },
        "f5634356c784403faab713da75a91647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be28c1c90fea4217b74a946b35c72068",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26427392/? [00:20&lt;00:00, 6715364.49it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf5c9eaeaf00442fa7fea1c044118c81"
          }
        },
        "5f68ddd1a5fe4c7f86905a8757da8ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c0ef20b6009424a96f4c856e943bcd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be28c1c90fea4217b74a946b35c72068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf5c9eaeaf00442fa7fea1c044118c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecbe8e7bf4d649178fac73e775eca3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45e0b013f3de4ed7830f45181772cff7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_83794ad7893640ae8ec1cf67708d6e6c",
              "IPY_MODEL_6a359466719d401b8d4471f0d9b03adb"
            ]
          }
        },
        "45e0b013f3de4ed7830f45181772cff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83794ad7893640ae8ec1cf67708d6e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ca9c1c71d614bd885c73481c6eb97a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e2bb970887d4682a3b3122eb3b8da38"
          }
        },
        "6a359466719d401b8d4471f0d9b03adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01e5df96fa8047ee988e51fcbdcce154",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32768/? [00:16&lt;00:00, 111818.81it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30b8532f6e6a4400a4be89deb26e1da6"
          }
        },
        "1ca9c1c71d614bd885c73481c6eb97a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e2bb970887d4682a3b3122eb3b8da38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01e5df96fa8047ee988e51fcbdcce154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30b8532f6e6a4400a4be89deb26e1da6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d4bd8399a094e89a3159d00e88ffa26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f40e3e080c824c15996ab24c295fd673",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f12a8aa80ea4d37b80bf8dbf14a874d",
              "IPY_MODEL_b3884c3b73b3420d8202efc9a4850b18"
            ]
          }
        },
        "f40e3e080c824c15996ab24c295fd673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f12a8aa80ea4d37b80bf8dbf14a874d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_47f214bc30f04a2688d87745e1e0c88f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83c6a7b2566d4ced9c411a87aa477bca"
          }
        },
        "b3884c3b73b3420d8202efc9a4850b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3922cda1a78949b1aa89a5dd3899fc56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4423680/? [00:02&lt;00:00, 2010846.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17d10bc9feca4b96ad7628cce17594bb"
          }
        },
        "47f214bc30f04a2688d87745e1e0c88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83c6a7b2566d4ced9c411a87aa477bca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3922cda1a78949b1aa89a5dd3899fc56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17d10bc9feca4b96ad7628cce17594bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbc68333e718450d8be3cc93defb3c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53011864be1f42d08a90aca28acaba03",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd6ff71d8e714afba7ef4f90f7fc12e9",
              "IPY_MODEL_4ee19685b4f44df89dbb5a4ffc28109f"
            ]
          }
        },
        "53011864be1f42d08a90aca28acaba03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd6ff71d8e714afba7ef4f90f7fc12e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d67e235e10114282b4fe332d10ab2172",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_786e9a2925ba4137bba306a35d4ba366"
          }
        },
        "4ee19685b4f44df89dbb5a4ffc28109f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f6c03f4f5ea2492796c0807aa617c83f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8192/? [00:00&lt;00:00, 13285.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cb139bbc813403daa7a4a3670b22ea5"
          }
        },
        "d67e235e10114282b4fe332d10ab2172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "786e9a2925ba4137bba306a35d4ba366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6c03f4f5ea2492796c0807aa617c83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cb139bbc813403daa7a4a3670b22ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakibreza/My-PyTorch-Playground/blob/master/Using_Optimizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBehvqZ8znsy",
        "colab_type": "text"
      },
      "source": [
        "# Using optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCdIqY0tKbvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting seeds to try and ensure we have the same results - this is not guaranteed across PyTorch releases.\n",
        "import torch\n",
        "torch.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PCJzXv0OK1Bs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383,
          "referenced_widgets": [
            "07a84345682a466dbbc8f7debc3feda6",
            "ae20146b93cb414296bb9642cab41d00",
            "5cc6a0fcc107484e9af323446755f50a",
            "f5634356c784403faab713da75a91647",
            "5f68ddd1a5fe4c7f86905a8757da8ab3",
            "9c0ef20b6009424a96f4c856e943bcd5",
            "be28c1c90fea4217b74a946b35c72068",
            "bf5c9eaeaf00442fa7fea1c044118c81",
            "ecbe8e7bf4d649178fac73e775eca3f2",
            "45e0b013f3de4ed7830f45181772cff7",
            "83794ad7893640ae8ec1cf67708d6e6c",
            "6a359466719d401b8d4471f0d9b03adb",
            "1ca9c1c71d614bd885c73481c6eb97a8",
            "8e2bb970887d4682a3b3122eb3b8da38",
            "01e5df96fa8047ee988e51fcbdcce154",
            "30b8532f6e6a4400a4be89deb26e1da6",
            "5d4bd8399a094e89a3159d00e88ffa26",
            "f40e3e080c824c15996ab24c295fd673",
            "5f12a8aa80ea4d37b80bf8dbf14a874d",
            "b3884c3b73b3420d8202efc9a4850b18",
            "47f214bc30f04a2688d87745e1e0c88f",
            "83c6a7b2566d4ced9c411a87aa477bca",
            "3922cda1a78949b1aa89a5dd3899fc56",
            "17d10bc9feca4b96ad7628cce17594bb",
            "dbc68333e718450d8be3cc93defb3c6a",
            "53011864be1f42d08a90aca28acaba03",
            "fd6ff71d8e714afba7ef4f90f7fc12e9",
            "4ee19685b4f44df89dbb5a4ffc28109f",
            "d67e235e10114282b4fe332d10ab2172",
            "786e9a2925ba4137bba306a35d4ba366",
            "f6c03f4f5ea2492796c0807aa617c83f",
            "2cb139bbc813403daa7a4a3670b22ea5"
          ]
        },
        "outputId": "32e0cf3f-945b-40dc-dadb-08ad1ad0c1e1"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "mean, std = (0.5,), (0.5,)\n",
        "\n",
        "# Create a transform and normalise data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean, std)\n",
        "                              ])\n",
        "\n",
        "# Download FMNIST training dataset and load training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download FMNIST test dataset and load test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/FMNIST/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07a84345682a466dbbc8f7debc3feda6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecbe8e7bf4d649178fac73e775eca3f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d4bd8399a094e89a3159d00e88ffa26",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbc68333e718450d8be3cc93defb3c6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/FMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/FMNIST/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqMqFbIVrbFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FMNIST(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784, 128)\n",
        "    self.fc2 = nn.Linear(128,64)\n",
        "    self.fc3 = nn.Linear(64,10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    \n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    \n",
        "    return x\n",
        "    \n",
        "#model = FMNIST()   "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c0QgxCF3fD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1ebac904-9eb1-4627-d73c-1749af236831"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iPQek2nz2yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMnVwV-CERd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roihp-kN0Jw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nf2WdmP5Gst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "247f4250-519e-43f8-ff75-701443caaa57"
      },
      "source": [
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Initial weights : ',model[0].weight)\n",
        "print('Initial weights gradient : ',model[0].weight.grad)\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights :  Parameter containing:\n",
            "tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
            "        [-0.0198, -0.0150, -0.0104,  ..., -0.0203, -0.0060, -0.0299],\n",
            "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
            "        ...,\n",
            "        [ 0.0018, -0.0295,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
            "        [-0.0233, -0.0220, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n",
            "        [ 0.0309,  0.0066,  0.0125,  ...,  0.0286,  0.0350, -0.0105]],\n",
            "       requires_grad=True)\n",
            "Initial weights gradient :  tensor([[-0.0004, -0.0004, -0.0004,  ..., -0.0007, -0.0006, -0.0004],\n",
            "        [ 0.0069,  0.0069,  0.0069,  ...,  0.0072,  0.0070,  0.0069],\n",
            "        [-0.0015, -0.0015, -0.0015,  ..., -0.0016, -0.0015, -0.0015],\n",
            "        ...,\n",
            "        [ 0.0018,  0.0018,  0.0018,  ...,  0.0017,  0.0017,  0.0018],\n",
            "        [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n",
            "        [ 0.0017,  0.0017,  0.0017,  ...,  0.0016,  0.0017,  0.0017]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arwzAK-1EkEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer.step()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuGKi_nq6P0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "c88bf5fb-5b0d-4632-a004-fcf22e5945f6"
      },
      "source": [
        "print('Initial weights : ',model[0].weight)\n",
        "print('Initial weights gradient : ',model[0].weight.grad)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights :  Parameter containing:\n",
            "tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
            "        [-0.0198, -0.0151, -0.0105,  ..., -0.0203, -0.0060, -0.0300],\n",
            "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
            "        ...,\n",
            "        [ 0.0018, -0.0296,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
            "        [-0.0233, -0.0221, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n",
            "        [ 0.0309,  0.0066,  0.0125,  ...,  0.0285,  0.0350, -0.0105]],\n",
            "       requires_grad=True)\n",
            "Initial weights gradient :  tensor([[-0.0004, -0.0004, -0.0004,  ..., -0.0007, -0.0006, -0.0004],\n",
            "        [ 0.0069,  0.0069,  0.0069,  ...,  0.0072,  0.0070,  0.0069],\n",
            "        [-0.0015, -0.0015, -0.0015,  ..., -0.0016, -0.0015, -0.0015],\n",
            "        ...,\n",
            "        [ 0.0018,  0.0018,  0.0018,  ...,  0.0017,  0.0017,  0.0018],\n",
            "        [ 0.0019,  0.0019,  0.0019,  ...,  0.0019,  0.0019,  0.0019],\n",
            "        [ 0.0017,  0.0017,  0.0017,  ...,  0.0016,  0.0017,  0.0017]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8oIy5SkEpDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer.zero_grad()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EniqxHDwDa8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "dbd23f5b-e913-45ee-900f-6b9909098636"
      },
      "source": [
        "print('Initial weights : ',model[0].weight)\n",
        "print('Initial weights gradient : ',model[0].weight.grad)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights :  Parameter containing:\n",
            "tensor([[-0.0003,  0.0192, -0.0294,  ...,  0.0219,  0.0037,  0.0021],\n",
            "        [-0.0198, -0.0151, -0.0105,  ..., -0.0203, -0.0060, -0.0300],\n",
            "        [-0.0201,  0.0149, -0.0333,  ..., -0.0203,  0.0012,  0.0080],\n",
            "        ...,\n",
            "        [ 0.0018, -0.0296,  0.0085,  ..., -0.0037,  0.0036,  0.0300],\n",
            "        [-0.0233, -0.0221, -0.0064,  ...,  0.0115, -0.0324, -0.0158],\n",
            "        [ 0.0309,  0.0066,  0.0125,  ...,  0.0285,  0.0350, -0.0105]],\n",
            "       requires_grad=True)\n",
            "Initial weights gradient :  tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGZhQE3tDcqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3540b1e6-0014-4307-ad8d-7f3313e454c9"
      },
      "source": [
        "model = FMNIST()\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    cum_loss = 0\n",
        "    batch_num = 0\n",
        "\n",
        "    for batch_num, (images, labels) in enumerate(trainloader, 1):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        cum_loss += loss.item()\n",
        "        print(f\"Batch: {batch_num}, Loss: {loss.item()}\")\n",
        "     \n",
        "    print(f\"Training loss: {cum_loss/len(trainloader)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch: 1, Loss: 2.3072664737701416\n",
            "Batch: 2, Loss: 2.288365364074707\n",
            "Batch: 3, Loss: 2.304906129837036\n",
            "Batch: 4, Loss: 2.3015007972717285\n",
            "Batch: 5, Loss: 2.278282642364502\n",
            "Batch: 6, Loss: 2.277097702026367\n",
            "Batch: 7, Loss: 2.2820229530334473\n",
            "Batch: 8, Loss: 2.3021080493927\n",
            "Batch: 9, Loss: 2.2785263061523438\n",
            "Batch: 10, Loss: 2.278015375137329\n",
            "Batch: 11, Loss: 2.2610418796539307\n",
            "Batch: 12, Loss: 2.2764644622802734\n",
            "Batch: 13, Loss: 2.2731387615203857\n",
            "Batch: 14, Loss: 2.2578248977661133\n",
            "Batch: 15, Loss: 2.2600483894348145\n",
            "Batch: 16, Loss: 2.261315107345581\n",
            "Batch: 17, Loss: 2.2721023559570312\n",
            "Batch: 18, Loss: 2.24147629737854\n",
            "Batch: 19, Loss: 2.2405261993408203\n",
            "Batch: 20, Loss: 2.235086441040039\n",
            "Batch: 21, Loss: 2.2544260025024414\n",
            "Batch: 22, Loss: 2.2362046241760254\n",
            "Batch: 23, Loss: 2.231415271759033\n",
            "Batch: 24, Loss: 2.2389469146728516\n",
            "Batch: 25, Loss: 2.2141687870025635\n",
            "Batch: 26, Loss: 2.233987331390381\n",
            "Batch: 27, Loss: 2.2178635597229004\n",
            "Batch: 28, Loss: 2.230189323425293\n",
            "Batch: 29, Loss: 2.2189369201660156\n",
            "Batch: 30, Loss: 2.2120749950408936\n",
            "Batch: 31, Loss: 2.212344169616699\n",
            "Batch: 32, Loss: 2.208530902862549\n",
            "Batch: 33, Loss: 2.18330717086792\n",
            "Batch: 34, Loss: 2.1965603828430176\n",
            "Batch: 35, Loss: 2.181426763534546\n",
            "Batch: 36, Loss: 2.2011210918426514\n",
            "Batch: 37, Loss: 2.196010112762451\n",
            "Batch: 38, Loss: 2.1590688228607178\n",
            "Batch: 39, Loss: 2.1497068405151367\n",
            "Batch: 40, Loss: 2.1899259090423584\n",
            "Batch: 41, Loss: 2.164797306060791\n",
            "Batch: 42, Loss: 2.176614761352539\n",
            "Batch: 43, Loss: 2.15094256401062\n",
            "Batch: 44, Loss: 2.1727468967437744\n",
            "Batch: 45, Loss: 2.149967670440674\n",
            "Batch: 46, Loss: 2.171332359313965\n",
            "Batch: 47, Loss: 2.1695690155029297\n",
            "Batch: 48, Loss: 2.1276767253875732\n",
            "Batch: 49, Loss: 2.138857126235962\n",
            "Batch: 50, Loss: 2.119607925415039\n",
            "Batch: 51, Loss: 2.155275583267212\n",
            "Batch: 52, Loss: 2.106316328048706\n",
            "Batch: 53, Loss: 2.162684202194214\n",
            "Batch: 54, Loss: 2.143470287322998\n",
            "Batch: 55, Loss: 2.122385025024414\n",
            "Batch: 56, Loss: 2.1170125007629395\n",
            "Batch: 57, Loss: 2.114706039428711\n",
            "Batch: 58, Loss: 2.1105237007141113\n",
            "Batch: 59, Loss: 2.1023786067962646\n",
            "Batch: 60, Loss: 2.1150588989257812\n",
            "Batch: 61, Loss: 2.1015803813934326\n",
            "Batch: 62, Loss: 2.099888324737549\n",
            "Batch: 63, Loss: 2.090914726257324\n",
            "Batch: 64, Loss: 2.1206960678100586\n",
            "Batch: 65, Loss: 2.1207191944122314\n",
            "Batch: 66, Loss: 2.0598037242889404\n",
            "Batch: 67, Loss: 2.088256359100342\n",
            "Batch: 68, Loss: 2.083505868911743\n",
            "Batch: 69, Loss: 2.0621414184570312\n",
            "Batch: 70, Loss: 2.07832407951355\n",
            "Batch: 71, Loss: 2.049839735031128\n",
            "Batch: 72, Loss: 2.101393699645996\n",
            "Batch: 73, Loss: 2.0119125843048096\n",
            "Batch: 74, Loss: 2.0472755432128906\n",
            "Batch: 75, Loss: 2.0591607093811035\n",
            "Batch: 76, Loss: 2.0145463943481445\n",
            "Batch: 77, Loss: 2.0132009983062744\n",
            "Batch: 78, Loss: 2.0692832469940186\n",
            "Batch: 79, Loss: 1.9742687940597534\n",
            "Batch: 80, Loss: 2.001490592956543\n",
            "Batch: 81, Loss: 2.0196759700775146\n",
            "Batch: 82, Loss: 2.000135660171509\n",
            "Batch: 83, Loss: 1.9519869089126587\n",
            "Batch: 84, Loss: 1.9761892557144165\n",
            "Batch: 85, Loss: 1.9856696128845215\n",
            "Batch: 86, Loss: 1.9579249620437622\n",
            "Batch: 87, Loss: 1.9509353637695312\n",
            "Batch: 88, Loss: 1.9740544557571411\n",
            "Batch: 89, Loss: 1.997693657875061\n",
            "Batch: 90, Loss: 1.9830443859100342\n",
            "Batch: 91, Loss: 1.9519984722137451\n",
            "Batch: 92, Loss: 1.995814323425293\n",
            "Batch: 93, Loss: 1.882996916770935\n",
            "Batch: 94, Loss: 1.9355740547180176\n",
            "Batch: 95, Loss: 1.9342939853668213\n",
            "Batch: 96, Loss: 1.9507614374160767\n",
            "Batch: 97, Loss: 1.9132921695709229\n",
            "Batch: 98, Loss: 1.8462460041046143\n",
            "Batch: 99, Loss: 1.9494209289550781\n",
            "Batch: 100, Loss: 1.9408873319625854\n",
            "Batch: 101, Loss: 1.8907982110977173\n",
            "Batch: 102, Loss: 1.8606395721435547\n",
            "Batch: 103, Loss: 1.9013184309005737\n",
            "Batch: 104, Loss: 1.8886555433273315\n",
            "Batch: 105, Loss: 1.8175097703933716\n",
            "Batch: 106, Loss: 1.8422013521194458\n",
            "Batch: 107, Loss: 1.8924274444580078\n",
            "Batch: 108, Loss: 1.8633681535720825\n",
            "Batch: 109, Loss: 1.8070480823516846\n",
            "Batch: 110, Loss: 1.8510231971740723\n",
            "Batch: 111, Loss: 1.864001989364624\n",
            "Batch: 112, Loss: 1.8724992275238037\n",
            "Batch: 113, Loss: 1.774314284324646\n",
            "Batch: 114, Loss: 1.7906323671340942\n",
            "Batch: 115, Loss: 1.7556573152542114\n",
            "Batch: 116, Loss: 1.8000102043151855\n",
            "Batch: 117, Loss: 1.8129258155822754\n",
            "Batch: 118, Loss: 1.7571617364883423\n",
            "Batch: 119, Loss: 1.7813451290130615\n",
            "Batch: 120, Loss: 1.7195903062820435\n",
            "Batch: 121, Loss: 1.7963536977767944\n",
            "Batch: 122, Loss: 1.8260608911514282\n",
            "Batch: 123, Loss: 1.7012096643447876\n",
            "Batch: 124, Loss: 1.808965802192688\n",
            "Batch: 125, Loss: 1.7685575485229492\n",
            "Batch: 126, Loss: 1.6843539476394653\n",
            "Batch: 127, Loss: 1.7526158094406128\n",
            "Batch: 128, Loss: 1.6819599866867065\n",
            "Batch: 129, Loss: 1.697723627090454\n",
            "Batch: 130, Loss: 1.676612377166748\n",
            "Batch: 131, Loss: 1.7065376043319702\n",
            "Batch: 132, Loss: 1.6822445392608643\n",
            "Batch: 133, Loss: 1.6404788494110107\n",
            "Batch: 134, Loss: 1.6830875873565674\n",
            "Batch: 135, Loss: 1.75214421749115\n",
            "Batch: 136, Loss: 1.7205088138580322\n",
            "Batch: 137, Loss: 1.6150269508361816\n",
            "Batch: 138, Loss: 1.6726666688919067\n",
            "Batch: 139, Loss: 1.6757068634033203\n",
            "Batch: 140, Loss: 1.6011085510253906\n",
            "Batch: 141, Loss: 1.6484205722808838\n",
            "Batch: 142, Loss: 1.570003628730774\n",
            "Batch: 143, Loss: 1.651314377784729\n",
            "Batch: 144, Loss: 1.5713629722595215\n",
            "Batch: 145, Loss: 1.5436736345291138\n",
            "Batch: 146, Loss: 1.5438709259033203\n",
            "Batch: 147, Loss: 1.5572839975357056\n",
            "Batch: 148, Loss: 1.5364141464233398\n",
            "Batch: 149, Loss: 1.5794425010681152\n",
            "Batch: 150, Loss: 1.5699447393417358\n",
            "Batch: 151, Loss: 1.508849859237671\n",
            "Batch: 152, Loss: 1.6017693281173706\n",
            "Batch: 153, Loss: 1.5836806297302246\n",
            "Batch: 154, Loss: 1.5391582250595093\n",
            "Batch: 155, Loss: 1.5011050701141357\n",
            "Batch: 156, Loss: 1.6004637479782104\n",
            "Batch: 157, Loss: 1.514003872871399\n",
            "Batch: 158, Loss: 1.6279891729354858\n",
            "Batch: 159, Loss: 1.5362401008605957\n",
            "Batch: 160, Loss: 1.4216476678848267\n",
            "Batch: 161, Loss: 1.4774826765060425\n",
            "Batch: 162, Loss: 1.4398096799850464\n",
            "Batch: 163, Loss: 1.3730343580245972\n",
            "Batch: 164, Loss: 1.4929624795913696\n",
            "Batch: 165, Loss: 1.5012770891189575\n",
            "Batch: 166, Loss: 1.5578880310058594\n",
            "Batch: 167, Loss: 1.449642539024353\n",
            "Batch: 168, Loss: 1.42793869972229\n",
            "Batch: 169, Loss: 1.4146183729171753\n",
            "Batch: 170, Loss: 1.5097516775131226\n",
            "Batch: 171, Loss: 1.453037142753601\n",
            "Batch: 172, Loss: 1.5306410789489746\n",
            "Batch: 173, Loss: 1.4319968223571777\n",
            "Batch: 174, Loss: 1.4024416208267212\n",
            "Batch: 175, Loss: 1.3567466735839844\n",
            "Batch: 176, Loss: 1.4077777862548828\n",
            "Batch: 177, Loss: 1.518044352531433\n",
            "Batch: 178, Loss: 1.4292813539505005\n",
            "Batch: 179, Loss: 1.360162377357483\n",
            "Batch: 180, Loss: 1.34250009059906\n",
            "Batch: 181, Loss: 1.3392082452774048\n",
            "Batch: 182, Loss: 1.3647029399871826\n",
            "Batch: 183, Loss: 1.418899655342102\n",
            "Batch: 184, Loss: 1.394244909286499\n",
            "Batch: 185, Loss: 1.5306984186172485\n",
            "Batch: 186, Loss: 1.3058139085769653\n",
            "Batch: 187, Loss: 1.2785077095031738\n",
            "Batch: 188, Loss: 1.3217579126358032\n",
            "Batch: 189, Loss: 1.3140453100204468\n",
            "Batch: 190, Loss: 1.451682686805725\n",
            "Batch: 191, Loss: 1.3721764087677002\n",
            "Batch: 192, Loss: 1.3867685794830322\n",
            "Batch: 193, Loss: 1.3851194381713867\n",
            "Batch: 194, Loss: 1.3192718029022217\n",
            "Batch: 195, Loss: 1.1872117519378662\n",
            "Batch: 196, Loss: 1.1685653924942017\n",
            "Batch: 197, Loss: 1.3811845779418945\n",
            "Batch: 198, Loss: 1.2313885688781738\n",
            "Batch: 199, Loss: 1.290045142173767\n",
            "Batch: 200, Loss: 1.2324146032333374\n",
            "Batch: 201, Loss: 1.276233434677124\n",
            "Batch: 202, Loss: 1.3471418619155884\n",
            "Batch: 203, Loss: 1.2543367147445679\n",
            "Batch: 204, Loss: 1.2662122249603271\n",
            "Batch: 205, Loss: 1.2558459043502808\n",
            "Batch: 206, Loss: 1.3018471002578735\n",
            "Batch: 207, Loss: 1.25498628616333\n",
            "Batch: 208, Loss: 1.2147616147994995\n",
            "Batch: 209, Loss: 1.1561082601547241\n",
            "Batch: 210, Loss: 1.1935949325561523\n",
            "Batch: 211, Loss: 1.3333455324172974\n",
            "Batch: 212, Loss: 1.1499519348144531\n",
            "Batch: 213, Loss: 1.2269110679626465\n",
            "Batch: 214, Loss: 1.2055678367614746\n",
            "Batch: 215, Loss: 1.1905691623687744\n",
            "Batch: 216, Loss: 1.2567012310028076\n",
            "Batch: 217, Loss: 1.2933361530303955\n",
            "Batch: 218, Loss: 1.2729896306991577\n",
            "Batch: 219, Loss: 1.1889132261276245\n",
            "Batch: 220, Loss: 1.2217456102371216\n",
            "Batch: 221, Loss: 1.1029069423675537\n",
            "Batch: 222, Loss: 1.143022894859314\n",
            "Batch: 223, Loss: 1.1383599042892456\n",
            "Batch: 224, Loss: 1.1079497337341309\n",
            "Batch: 225, Loss: 1.1150227785110474\n",
            "Batch: 226, Loss: 1.2556616067886353\n",
            "Batch: 227, Loss: 1.170961856842041\n",
            "Batch: 228, Loss: 1.317028284072876\n",
            "Batch: 229, Loss: 1.2025264501571655\n",
            "Batch: 230, Loss: 1.1310453414916992\n",
            "Batch: 231, Loss: 1.1437819004058838\n",
            "Batch: 232, Loss: 1.2180911302566528\n",
            "Batch: 233, Loss: 1.1097800731658936\n",
            "Batch: 234, Loss: 1.1782920360565186\n",
            "Batch: 235, Loss: 1.1602427959442139\n",
            "Batch: 236, Loss: 1.059375524520874\n",
            "Batch: 237, Loss: 1.2130478620529175\n",
            "Batch: 238, Loss: 1.1346352100372314\n",
            "Batch: 239, Loss: 1.0951237678527832\n",
            "Batch: 240, Loss: 1.1449997425079346\n",
            "Batch: 241, Loss: 1.1075793504714966\n",
            "Batch: 242, Loss: 1.2723548412322998\n",
            "Batch: 243, Loss: 1.2597426176071167\n",
            "Batch: 244, Loss: 1.180441975593567\n",
            "Batch: 245, Loss: 1.0977140665054321\n",
            "Batch: 246, Loss: 1.0899471044540405\n",
            "Batch: 247, Loss: 1.030632495880127\n",
            "Batch: 248, Loss: 1.2047559022903442\n",
            "Batch: 249, Loss: 1.0198942422866821\n",
            "Batch: 250, Loss: 1.0587043762207031\n",
            "Batch: 251, Loss: 1.0523439645767212\n",
            "Batch: 252, Loss: 1.0425925254821777\n",
            "Batch: 253, Loss: 1.0443549156188965\n",
            "Batch: 254, Loss: 0.9958981275558472\n",
            "Batch: 255, Loss: 1.1265822649002075\n",
            "Batch: 256, Loss: 1.1265720129013062\n",
            "Batch: 257, Loss: 1.0676978826522827\n",
            "Batch: 258, Loss: 0.982078492641449\n",
            "Batch: 259, Loss: 1.0893367528915405\n",
            "Batch: 260, Loss: 1.0720278024673462\n",
            "Batch: 261, Loss: 1.0170844793319702\n",
            "Batch: 262, Loss: 1.0822778940200806\n",
            "Batch: 263, Loss: 1.126015543937683\n",
            "Batch: 264, Loss: 1.1336655616760254\n",
            "Batch: 265, Loss: 1.0612192153930664\n",
            "Batch: 266, Loss: 1.031455397605896\n",
            "Batch: 267, Loss: 0.9730389714241028\n",
            "Batch: 268, Loss: 1.046057105064392\n",
            "Batch: 269, Loss: 1.109437108039856\n",
            "Batch: 270, Loss: 0.9424539804458618\n",
            "Batch: 271, Loss: 1.0871316194534302\n",
            "Batch: 272, Loss: 1.1134552955627441\n",
            "Batch: 273, Loss: 1.1059632301330566\n",
            "Batch: 274, Loss: 0.951941192150116\n",
            "Batch: 275, Loss: 0.9635064601898193\n",
            "Batch: 276, Loss: 1.029418706893921\n",
            "Batch: 277, Loss: 1.1684489250183105\n",
            "Batch: 278, Loss: 1.1614446640014648\n",
            "Batch: 279, Loss: 0.9837824106216431\n",
            "Batch: 280, Loss: 0.9699404239654541\n",
            "Batch: 281, Loss: 1.1427991390228271\n",
            "Batch: 282, Loss: 0.8685055375099182\n",
            "Batch: 283, Loss: 0.8392717242240906\n",
            "Batch: 284, Loss: 1.0241713523864746\n",
            "Batch: 285, Loss: 0.9343221783638\n",
            "Batch: 286, Loss: 1.0498000383377075\n",
            "Batch: 287, Loss: 1.077364206314087\n",
            "Batch: 288, Loss: 1.0138649940490723\n",
            "Batch: 289, Loss: 1.0758299827575684\n",
            "Batch: 290, Loss: 1.0646798610687256\n",
            "Batch: 291, Loss: 0.905829668045044\n",
            "Batch: 292, Loss: 0.9696572422981262\n",
            "Batch: 293, Loss: 1.0727152824401855\n",
            "Batch: 294, Loss: 0.8240320682525635\n",
            "Batch: 295, Loss: 0.978036105632782\n",
            "Batch: 296, Loss: 1.0660444498062134\n",
            "Batch: 297, Loss: 0.9996482133865356\n",
            "Batch: 298, Loss: 1.0516557693481445\n",
            "Batch: 299, Loss: 0.9114246368408203\n",
            "Batch: 300, Loss: 0.921526312828064\n",
            "Batch: 301, Loss: 0.9720900654792786\n",
            "Batch: 302, Loss: 1.0234334468841553\n",
            "Batch: 303, Loss: 0.8493380546569824\n",
            "Batch: 304, Loss: 0.8582993745803833\n",
            "Batch: 305, Loss: 0.9090601801872253\n",
            "Batch: 306, Loss: 1.0527397394180298\n",
            "Batch: 307, Loss: 1.0491597652435303\n",
            "Batch: 308, Loss: 0.9200174808502197\n",
            "Batch: 309, Loss: 0.9986163973808289\n",
            "Batch: 310, Loss: 0.9688748717308044\n",
            "Batch: 311, Loss: 0.9578299522399902\n",
            "Batch: 312, Loss: 0.9689343571662903\n",
            "Batch: 313, Loss: 0.8711985349655151\n",
            "Batch: 314, Loss: 0.9280243515968323\n",
            "Batch: 315, Loss: 0.94105464220047\n",
            "Batch: 316, Loss: 0.9093227386474609\n",
            "Batch: 317, Loss: 0.9657814502716064\n",
            "Batch: 318, Loss: 0.8934503197669983\n",
            "Batch: 319, Loss: 1.0389132499694824\n",
            "Batch: 320, Loss: 0.8316049575805664\n",
            "Batch: 321, Loss: 1.1061925888061523\n",
            "Batch: 322, Loss: 1.1641439199447632\n",
            "Batch: 323, Loss: 1.017019510269165\n",
            "Batch: 324, Loss: 0.8632962703704834\n",
            "Batch: 325, Loss: 0.9171527028083801\n",
            "Batch: 326, Loss: 0.8784530162811279\n",
            "Batch: 327, Loss: 0.896760106086731\n",
            "Batch: 328, Loss: 0.8556399345397949\n",
            "Batch: 329, Loss: 0.8671011328697205\n",
            "Batch: 330, Loss: 0.8803450465202332\n",
            "Batch: 331, Loss: 0.9032302498817444\n",
            "Batch: 332, Loss: 1.0007147789001465\n",
            "Batch: 333, Loss: 0.9165623188018799\n",
            "Batch: 334, Loss: 1.0124568939208984\n",
            "Batch: 335, Loss: 0.9100621938705444\n",
            "Batch: 336, Loss: 0.9086296558380127\n",
            "Batch: 337, Loss: 0.8260985016822815\n",
            "Batch: 338, Loss: 0.8282187581062317\n",
            "Batch: 339, Loss: 0.923349142074585\n",
            "Batch: 340, Loss: 0.802649974822998\n",
            "Batch: 341, Loss: 0.8284263014793396\n",
            "Batch: 342, Loss: 0.7605389952659607\n",
            "Batch: 343, Loss: 0.8705877661705017\n",
            "Batch: 344, Loss: 0.8520339131355286\n",
            "Batch: 345, Loss: 0.7647964358329773\n",
            "Batch: 346, Loss: 0.9043696522712708\n",
            "Batch: 347, Loss: 0.8804537057876587\n",
            "Batch: 348, Loss: 0.9027995467185974\n",
            "Batch: 349, Loss: 0.8458782434463501\n",
            "Batch: 350, Loss: 0.7979928255081177\n",
            "Batch: 351, Loss: 0.8782753944396973\n",
            "Batch: 352, Loss: 0.8830074667930603\n",
            "Batch: 353, Loss: 0.8684967756271362\n",
            "Batch: 354, Loss: 0.815262496471405\n",
            "Batch: 355, Loss: 0.787391722202301\n",
            "Batch: 356, Loss: 0.8207087516784668\n",
            "Batch: 357, Loss: 0.8063499331474304\n",
            "Batch: 358, Loss: 0.9580703377723694\n",
            "Batch: 359, Loss: 0.8938490748405457\n",
            "Batch: 360, Loss: 0.8493978977203369\n",
            "Batch: 361, Loss: 0.7761769890785217\n",
            "Batch: 362, Loss: 0.9212706685066223\n",
            "Batch: 363, Loss: 0.897742748260498\n",
            "Batch: 364, Loss: 0.823185384273529\n",
            "Batch: 365, Loss: 0.7342697381973267\n",
            "Batch: 366, Loss: 0.9282716512680054\n",
            "Batch: 367, Loss: 0.9211367964744568\n",
            "Batch: 368, Loss: 1.0930038690567017\n",
            "Batch: 369, Loss: 0.8094150424003601\n",
            "Batch: 370, Loss: 0.8239570260047913\n",
            "Batch: 371, Loss: 0.9299612641334534\n",
            "Batch: 372, Loss: 0.9884332418441772\n",
            "Batch: 373, Loss: 0.8688575029373169\n",
            "Batch: 374, Loss: 0.9317647218704224\n",
            "Batch: 375, Loss: 1.0074979066848755\n",
            "Batch: 376, Loss: 0.7230299115180969\n",
            "Batch: 377, Loss: 0.9265599250793457\n",
            "Batch: 378, Loss: 0.7993811368942261\n",
            "Batch: 379, Loss: 0.8453940153121948\n",
            "Batch: 380, Loss: 0.8845804929733276\n",
            "Batch: 381, Loss: 0.7797443866729736\n",
            "Batch: 382, Loss: 0.8439711332321167\n",
            "Batch: 383, Loss: 0.9713020324707031\n",
            "Batch: 384, Loss: 0.8521345853805542\n",
            "Batch: 385, Loss: 0.8878020644187927\n",
            "Batch: 386, Loss: 0.8182076215744019\n",
            "Batch: 387, Loss: 0.827324390411377\n",
            "Batch: 388, Loss: 0.7920875549316406\n",
            "Batch: 389, Loss: 1.0852773189544678\n",
            "Batch: 390, Loss: 0.9102339148521423\n",
            "Batch: 391, Loss: 0.8707335591316223\n",
            "Batch: 392, Loss: 0.8671579360961914\n",
            "Batch: 393, Loss: 0.9126366972923279\n",
            "Batch: 394, Loss: 0.7354848384857178\n",
            "Batch: 395, Loss: 0.8450466990470886\n",
            "Batch: 396, Loss: 0.8794946670532227\n",
            "Batch: 397, Loss: 0.8245577216148376\n",
            "Batch: 398, Loss: 0.7831891775131226\n",
            "Batch: 399, Loss: 0.8343012928962708\n",
            "Batch: 400, Loss: 0.8914602398872375\n",
            "Batch: 401, Loss: 0.8135738372802734\n",
            "Batch: 402, Loss: 0.8037071824073792\n",
            "Batch: 403, Loss: 0.8829104900360107\n",
            "Batch: 404, Loss: 0.796343207359314\n",
            "Batch: 405, Loss: 0.9002365469932556\n",
            "Batch: 406, Loss: 0.7158209681510925\n",
            "Batch: 407, Loss: 0.9091522097587585\n",
            "Batch: 408, Loss: 0.766260027885437\n",
            "Batch: 409, Loss: 0.7814144492149353\n",
            "Batch: 410, Loss: 0.8427134156227112\n",
            "Batch: 411, Loss: 0.7641225457191467\n",
            "Batch: 412, Loss: 0.7864933609962463\n",
            "Batch: 413, Loss: 0.7474682331085205\n",
            "Batch: 414, Loss: 0.657743513584137\n",
            "Batch: 415, Loss: 0.8480469584465027\n",
            "Batch: 416, Loss: 0.79021155834198\n",
            "Batch: 417, Loss: 0.8062776327133179\n",
            "Batch: 418, Loss: 0.83390212059021\n",
            "Batch: 419, Loss: 0.7854911088943481\n",
            "Batch: 420, Loss: 0.8026905059814453\n",
            "Batch: 421, Loss: 0.9773293137550354\n",
            "Batch: 422, Loss: 0.7197680473327637\n",
            "Batch: 423, Loss: 0.8526830077171326\n",
            "Batch: 424, Loss: 0.6799077987670898\n",
            "Batch: 425, Loss: 0.8209723234176636\n",
            "Batch: 426, Loss: 0.783911406993866\n",
            "Batch: 427, Loss: 0.7291870713233948\n",
            "Batch: 428, Loss: 0.8702353835105896\n",
            "Batch: 429, Loss: 0.7280413508415222\n",
            "Batch: 430, Loss: 0.7339926958084106\n",
            "Batch: 431, Loss: 0.8574195504188538\n",
            "Batch: 432, Loss: 0.8005540370941162\n",
            "Batch: 433, Loss: 0.7386953234672546\n",
            "Batch: 434, Loss: 0.8094177842140198\n",
            "Batch: 435, Loss: 0.7776733040809631\n",
            "Batch: 436, Loss: 0.8416813015937805\n",
            "Batch: 437, Loss: 0.680239737033844\n",
            "Batch: 438, Loss: 0.8614040613174438\n",
            "Batch: 439, Loss: 0.8386146426200867\n",
            "Batch: 440, Loss: 0.7010176181793213\n",
            "Batch: 441, Loss: 0.9777506589889526\n",
            "Batch: 442, Loss: 0.8315463662147522\n",
            "Batch: 443, Loss: 0.5960734486579895\n",
            "Batch: 444, Loss: 0.8287419080734253\n",
            "Batch: 445, Loss: 0.6986140608787537\n",
            "Batch: 446, Loss: 0.6867812275886536\n",
            "Batch: 447, Loss: 0.8329377174377441\n",
            "Batch: 448, Loss: 0.9519304037094116\n",
            "Batch: 449, Loss: 1.013325810432434\n",
            "Batch: 450, Loss: 0.8764013051986694\n",
            "Batch: 451, Loss: 0.6130232810974121\n",
            "Batch: 452, Loss: 0.8226187825202942\n",
            "Batch: 453, Loss: 0.8953377604484558\n",
            "Batch: 454, Loss: 0.9911093711853027\n",
            "Batch: 455, Loss: 0.6610314249992371\n",
            "Batch: 456, Loss: 0.8318133354187012\n",
            "Batch: 457, Loss: 0.734184741973877\n",
            "Batch: 458, Loss: 0.8478312492370605\n",
            "Batch: 459, Loss: 0.7626639604568481\n",
            "Batch: 460, Loss: 0.7000948190689087\n",
            "Batch: 461, Loss: 0.901291012763977\n",
            "Batch: 462, Loss: 0.7903916239738464\n",
            "Batch: 463, Loss: 0.7858090996742249\n",
            "Batch: 464, Loss: 0.725614070892334\n",
            "Batch: 465, Loss: 0.6941235065460205\n",
            "Batch: 466, Loss: 0.618312418460846\n",
            "Batch: 467, Loss: 0.5954136848449707\n",
            "Batch: 468, Loss: 0.7560440301895142\n",
            "Batch: 469, Loss: 0.8390430212020874\n",
            "Batch: 470, Loss: 0.8511555790901184\n",
            "Batch: 471, Loss: 0.7293270826339722\n",
            "Batch: 472, Loss: 0.7080273628234863\n",
            "Batch: 473, Loss: 0.7914901375770569\n",
            "Batch: 474, Loss: 0.7658335566520691\n",
            "Batch: 475, Loss: 0.7631339430809021\n",
            "Batch: 476, Loss: 0.907961905002594\n",
            "Batch: 477, Loss: 0.7090212106704712\n",
            "Batch: 478, Loss: 0.8651058077812195\n",
            "Batch: 479, Loss: 1.0298246145248413\n",
            "Batch: 480, Loss: 0.7285560369491577\n",
            "Batch: 481, Loss: 0.7956752777099609\n",
            "Batch: 482, Loss: 0.6916142702102661\n",
            "Batch: 483, Loss: 0.7819523811340332\n",
            "Batch: 484, Loss: 0.7953404188156128\n",
            "Batch: 485, Loss: 0.848452091217041\n",
            "Batch: 486, Loss: 0.645694375038147\n",
            "Batch: 487, Loss: 0.7878633141517639\n",
            "Batch: 488, Loss: 0.5788812041282654\n",
            "Batch: 489, Loss: 0.9018926024436951\n",
            "Batch: 490, Loss: 1.0051319599151611\n",
            "Batch: 491, Loss: 0.8162555694580078\n",
            "Batch: 492, Loss: 0.7170443534851074\n",
            "Batch: 493, Loss: 0.9623134732246399\n",
            "Batch: 494, Loss: 0.7212497591972351\n",
            "Batch: 495, Loss: 0.8200948238372803\n",
            "Batch: 496, Loss: 0.8428404927253723\n",
            "Batch: 497, Loss: 0.8266487717628479\n",
            "Batch: 498, Loss: 0.728888988494873\n",
            "Batch: 499, Loss: 0.6201906800270081\n",
            "Batch: 500, Loss: 0.6668667793273926\n",
            "Batch: 501, Loss: 0.7001542448997498\n",
            "Batch: 502, Loss: 0.7390239238739014\n",
            "Batch: 503, Loss: 0.7694615125656128\n",
            "Batch: 504, Loss: 0.6881656646728516\n",
            "Batch: 505, Loss: 0.7486899495124817\n",
            "Batch: 506, Loss: 0.7178452610969543\n",
            "Batch: 507, Loss: 0.764504075050354\n",
            "Batch: 508, Loss: 0.8180655241012573\n",
            "Batch: 509, Loss: 0.626116931438446\n",
            "Batch: 510, Loss: 0.5757691264152527\n",
            "Batch: 511, Loss: 0.6368715763092041\n",
            "Batch: 512, Loss: 0.8209702372550964\n",
            "Batch: 513, Loss: 0.6571943163871765\n",
            "Batch: 514, Loss: 0.8181226849555969\n",
            "Batch: 515, Loss: 0.8991817235946655\n",
            "Batch: 516, Loss: 0.5987187027931213\n",
            "Batch: 517, Loss: 0.7104390859603882\n",
            "Batch: 518, Loss: 0.6955272555351257\n",
            "Batch: 519, Loss: 0.7668682932853699\n",
            "Batch: 520, Loss: 0.6248461604118347\n",
            "Batch: 521, Loss: 0.7633218765258789\n",
            "Batch: 522, Loss: 0.7639679908752441\n",
            "Batch: 523, Loss: 0.6813908815383911\n",
            "Batch: 524, Loss: 0.7032680511474609\n",
            "Batch: 525, Loss: 0.8158365488052368\n",
            "Batch: 526, Loss: 0.7008258700370789\n",
            "Batch: 527, Loss: 0.7318704128265381\n",
            "Batch: 528, Loss: 0.8237457275390625\n",
            "Batch: 529, Loss: 0.7302277684211731\n",
            "Batch: 530, Loss: 0.8000780344009399\n",
            "Batch: 531, Loss: 0.7459021210670471\n",
            "Batch: 532, Loss: 0.6744062304496765\n",
            "Batch: 533, Loss: 0.6209844946861267\n",
            "Batch: 534, Loss: 0.6043549180030823\n",
            "Batch: 535, Loss: 0.7153635621070862\n",
            "Batch: 536, Loss: 0.767081081867218\n",
            "Batch: 537, Loss: 0.7152273058891296\n",
            "Batch: 538, Loss: 0.7836175560951233\n",
            "Batch: 539, Loss: 0.8859688639640808\n",
            "Batch: 540, Loss: 0.5995661616325378\n",
            "Batch: 541, Loss: 0.7726280093193054\n",
            "Batch: 542, Loss: 0.807292640209198\n",
            "Batch: 543, Loss: 0.6856865882873535\n",
            "Batch: 544, Loss: 0.8178539276123047\n",
            "Batch: 545, Loss: 0.7820209860801697\n",
            "Batch: 546, Loss: 0.6277299523353577\n",
            "Batch: 547, Loss: 0.6063003540039062\n",
            "Batch: 548, Loss: 0.5771196484565735\n",
            "Batch: 549, Loss: 0.7162109613418579\n",
            "Batch: 550, Loss: 0.7243057489395142\n",
            "Batch: 551, Loss: 0.6795232892036438\n",
            "Batch: 552, Loss: 0.6875499486923218\n",
            "Batch: 553, Loss: 0.6337344646453857\n",
            "Batch: 554, Loss: 0.7657601833343506\n",
            "Batch: 555, Loss: 0.5945144891738892\n",
            "Batch: 556, Loss: 0.7037349343299866\n",
            "Batch: 557, Loss: 0.5918629765510559\n",
            "Batch: 558, Loss: 0.7345333099365234\n",
            "Batch: 559, Loss: 0.7458140850067139\n",
            "Batch: 560, Loss: 0.6451553106307983\n",
            "Batch: 561, Loss: 0.7310765981674194\n",
            "Batch: 562, Loss: 0.7158867120742798\n",
            "Batch: 563, Loss: 0.5862026810646057\n",
            "Batch: 564, Loss: 0.6607757210731506\n",
            "Batch: 565, Loss: 0.7020208835601807\n",
            "Batch: 566, Loss: 0.676846981048584\n",
            "Batch: 567, Loss: 0.568358838558197\n",
            "Batch: 568, Loss: 0.8122460246086121\n",
            "Batch: 569, Loss: 0.8262038826942444\n",
            "Batch: 570, Loss: 0.5531500577926636\n",
            "Batch: 571, Loss: 0.8177270293235779\n",
            "Batch: 572, Loss: 0.6182724833488464\n",
            "Batch: 573, Loss: 0.8577132821083069\n",
            "Batch: 574, Loss: 0.687988817691803\n",
            "Batch: 575, Loss: 0.8024770021438599\n",
            "Batch: 576, Loss: 0.644985020160675\n",
            "Batch: 577, Loss: 0.8956262469291687\n",
            "Batch: 578, Loss: 0.8353311419487\n",
            "Batch: 579, Loss: 0.7226056456565857\n",
            "Batch: 580, Loss: 0.6427013874053955\n",
            "Batch: 581, Loss: 0.7412430644035339\n",
            "Batch: 582, Loss: 0.8084627389907837\n",
            "Batch: 583, Loss: 0.7360825538635254\n",
            "Batch: 584, Loss: 0.7131630182266235\n",
            "Batch: 585, Loss: 0.6824694871902466\n",
            "Batch: 586, Loss: 0.8416376709938049\n",
            "Batch: 587, Loss: 0.7754369974136353\n",
            "Batch: 588, Loss: 0.6350184082984924\n",
            "Batch: 589, Loss: 0.7927234768867493\n",
            "Batch: 590, Loss: 0.6105597615242004\n",
            "Batch: 591, Loss: 0.5839828252792358\n",
            "Batch: 592, Loss: 0.6542515754699707\n",
            "Batch: 593, Loss: 0.6945108771324158\n",
            "Batch: 594, Loss: 0.7460647225379944\n",
            "Batch: 595, Loss: 0.7481682896614075\n",
            "Batch: 596, Loss: 0.6829921007156372\n",
            "Batch: 597, Loss: 0.9021748304367065\n",
            "Batch: 598, Loss: 0.6492428183555603\n",
            "Batch: 599, Loss: 0.5841835737228394\n",
            "Batch: 600, Loss: 0.6647477746009827\n",
            "Batch: 601, Loss: 0.817363977432251\n",
            "Batch: 602, Loss: 0.5498621463775635\n",
            "Batch: 603, Loss: 0.6409099102020264\n",
            "Batch: 604, Loss: 0.8024592995643616\n",
            "Batch: 605, Loss: 0.7065194845199585\n",
            "Batch: 606, Loss: 0.7493241429328918\n",
            "Batch: 607, Loss: 0.5115584135055542\n",
            "Batch: 608, Loss: 0.7923208475112915\n",
            "Batch: 609, Loss: 0.7311131358146667\n",
            "Batch: 610, Loss: 0.7547754645347595\n",
            "Batch: 611, Loss: 0.7429410219192505\n",
            "Batch: 612, Loss: 0.7045831084251404\n",
            "Batch: 613, Loss: 0.7515861392021179\n",
            "Batch: 614, Loss: 0.7577176690101624\n",
            "Batch: 615, Loss: 0.8686426281929016\n",
            "Batch: 616, Loss: 0.8833822011947632\n",
            "Batch: 617, Loss: 0.5212948322296143\n",
            "Batch: 618, Loss: 0.801815927028656\n",
            "Batch: 619, Loss: 0.6853581070899963\n",
            "Batch: 620, Loss: 0.6867836713790894\n",
            "Batch: 621, Loss: 0.8388172388076782\n",
            "Batch: 622, Loss: 0.8420730233192444\n",
            "Batch: 623, Loss: 0.8181005716323853\n",
            "Batch: 624, Loss: 0.8232707977294922\n",
            "Batch: 625, Loss: 0.5072008371353149\n",
            "Batch: 626, Loss: 0.7882265448570251\n",
            "Batch: 627, Loss: 0.7044596672058105\n",
            "Batch: 628, Loss: 0.8803495168685913\n",
            "Batch: 629, Loss: 0.8332690000534058\n",
            "Batch: 630, Loss: 0.6668520569801331\n",
            "Batch: 631, Loss: 0.6573176980018616\n",
            "Batch: 632, Loss: 0.715943455696106\n",
            "Batch: 633, Loss: 0.6666923761367798\n",
            "Batch: 634, Loss: 0.5520530343055725\n",
            "Batch: 635, Loss: 0.6403948664665222\n",
            "Batch: 636, Loss: 0.6086441278457642\n",
            "Batch: 637, Loss: 0.5769174098968506\n",
            "Batch: 638, Loss: 0.7067503333091736\n",
            "Batch: 639, Loss: 0.6889974474906921\n",
            "Batch: 640, Loss: 0.7404849529266357\n",
            "Batch: 641, Loss: 0.5796242356300354\n",
            "Batch: 642, Loss: 0.6452949047088623\n",
            "Batch: 643, Loss: 0.660976231098175\n",
            "Batch: 644, Loss: 0.6699578166007996\n",
            "Batch: 645, Loss: 0.5862603187561035\n",
            "Batch: 646, Loss: 0.7123630046844482\n",
            "Batch: 647, Loss: 0.6703590750694275\n",
            "Batch: 648, Loss: 0.5812422633171082\n",
            "Batch: 649, Loss: 0.6934174299240112\n",
            "Batch: 650, Loss: 0.7670720815658569\n",
            "Batch: 651, Loss: 0.6700172424316406\n",
            "Batch: 652, Loss: 0.5952284336090088\n",
            "Batch: 653, Loss: 0.6965495944023132\n",
            "Batch: 654, Loss: 0.6747641563415527\n",
            "Batch: 655, Loss: 0.7032652497291565\n",
            "Batch: 656, Loss: 0.7302454710006714\n",
            "Batch: 657, Loss: 0.6455639004707336\n",
            "Batch: 658, Loss: 0.8688472509384155\n",
            "Batch: 659, Loss: 0.6208707094192505\n",
            "Batch: 660, Loss: 0.6904845833778381\n",
            "Batch: 661, Loss: 0.8703556656837463\n",
            "Batch: 662, Loss: 0.5169525742530823\n",
            "Batch: 663, Loss: 0.7158976197242737\n",
            "Batch: 664, Loss: 0.6938871145248413\n",
            "Batch: 665, Loss: 0.7605727314949036\n",
            "Batch: 666, Loss: 0.7405463457107544\n",
            "Batch: 667, Loss: 0.5392226576805115\n",
            "Batch: 668, Loss: 0.6232936382293701\n",
            "Batch: 669, Loss: 0.7491416931152344\n",
            "Batch: 670, Loss: 0.6374930739402771\n",
            "Batch: 671, Loss: 0.6097741723060608\n",
            "Batch: 672, Loss: 0.7418580055236816\n",
            "Batch: 673, Loss: 0.692225992679596\n",
            "Batch: 674, Loss: 0.7241102457046509\n",
            "Batch: 675, Loss: 0.7333393692970276\n",
            "Batch: 676, Loss: 0.7154023051261902\n",
            "Batch: 677, Loss: 0.6741828322410583\n",
            "Batch: 678, Loss: 0.7108805179595947\n",
            "Batch: 679, Loss: 0.6717433333396912\n",
            "Batch: 680, Loss: 0.5247433185577393\n",
            "Batch: 681, Loss: 0.6983130574226379\n",
            "Batch: 682, Loss: 0.5820331573486328\n",
            "Batch: 683, Loss: 0.6886465549468994\n",
            "Batch: 684, Loss: 0.606579601764679\n",
            "Batch: 685, Loss: 0.7954822778701782\n",
            "Batch: 686, Loss: 0.6436346173286438\n",
            "Batch: 687, Loss: 0.5862751007080078\n",
            "Batch: 688, Loss: 0.5565547943115234\n",
            "Batch: 689, Loss: 0.594443678855896\n",
            "Batch: 690, Loss: 0.3818419277667999\n",
            "Batch: 691, Loss: 0.6102442145347595\n",
            "Batch: 692, Loss: 0.8900747895240784\n",
            "Batch: 693, Loss: 0.7483469247817993\n",
            "Batch: 694, Loss: 0.5845595598220825\n",
            "Batch: 695, Loss: 0.7340801954269409\n",
            "Batch: 696, Loss: 0.7673280239105225\n",
            "Batch: 697, Loss: 0.7287828922271729\n",
            "Batch: 698, Loss: 0.7086018323898315\n",
            "Batch: 699, Loss: 0.5820657014846802\n",
            "Batch: 700, Loss: 0.79509437084198\n",
            "Batch: 701, Loss: 0.8860697150230408\n",
            "Batch: 702, Loss: 0.6280319094657898\n",
            "Batch: 703, Loss: 0.6109765768051147\n",
            "Batch: 704, Loss: 0.6117637753486633\n",
            "Batch: 705, Loss: 0.46953102946281433\n",
            "Batch: 706, Loss: 0.707882821559906\n",
            "Batch: 707, Loss: 0.6985652446746826\n",
            "Batch: 708, Loss: 0.6303344964981079\n",
            "Batch: 709, Loss: 0.5704299211502075\n",
            "Batch: 710, Loss: 0.8939830660820007\n",
            "Batch: 711, Loss: 0.6500504612922668\n",
            "Batch: 712, Loss: 0.7543462514877319\n",
            "Batch: 713, Loss: 0.6225394010543823\n",
            "Batch: 714, Loss: 0.5027394890785217\n",
            "Batch: 715, Loss: 0.659058153629303\n",
            "Batch: 716, Loss: 0.5006905198097229\n",
            "Batch: 717, Loss: 0.7125397324562073\n",
            "Batch: 718, Loss: 0.7808570861816406\n",
            "Batch: 719, Loss: 0.6571108102798462\n",
            "Batch: 720, Loss: 0.5399575233459473\n",
            "Batch: 721, Loss: 0.5487465858459473\n",
            "Batch: 722, Loss: 0.6594753861427307\n",
            "Batch: 723, Loss: 0.7550454139709473\n",
            "Batch: 724, Loss: 0.6160656213760376\n",
            "Batch: 725, Loss: 0.6684433221817017\n",
            "Batch: 726, Loss: 0.804412841796875\n",
            "Batch: 727, Loss: 0.7366745471954346\n",
            "Batch: 728, Loss: 0.803022027015686\n",
            "Batch: 729, Loss: 0.5814359188079834\n",
            "Batch: 730, Loss: 0.6982653141021729\n",
            "Batch: 731, Loss: 0.6443042159080505\n",
            "Batch: 732, Loss: 0.5783629417419434\n",
            "Batch: 733, Loss: 0.5967876315116882\n",
            "Batch: 734, Loss: 0.5850093960762024\n",
            "Batch: 735, Loss: 0.5939128994941711\n",
            "Batch: 736, Loss: 0.7183687090873718\n",
            "Batch: 737, Loss: 0.5253506302833557\n",
            "Batch: 738, Loss: 0.6589365601539612\n",
            "Batch: 739, Loss: 0.801835834980011\n",
            "Batch: 740, Loss: 0.66390061378479\n",
            "Batch: 741, Loss: 0.6596941351890564\n",
            "Batch: 742, Loss: 0.7839537858963013\n",
            "Batch: 743, Loss: 0.6642365455627441\n",
            "Batch: 744, Loss: 0.7208248972892761\n",
            "Batch: 745, Loss: 0.5461099147796631\n",
            "Batch: 746, Loss: 0.6773321032524109\n",
            "Batch: 747, Loss: 0.6989396214485168\n",
            "Batch: 748, Loss: 0.5112060904502869\n",
            "Batch: 749, Loss: 0.5222391486167908\n",
            "Batch: 750, Loss: 0.5779560208320618\n",
            "Batch: 751, Loss: 0.5782550573348999\n",
            "Batch: 752, Loss: 0.7588960528373718\n",
            "Batch: 753, Loss: 0.4941641092300415\n",
            "Batch: 754, Loss: 0.5813581347465515\n",
            "Batch: 755, Loss: 0.6940640807151794\n",
            "Batch: 756, Loss: 0.643857479095459\n",
            "Batch: 757, Loss: 0.6889374256134033\n",
            "Batch: 758, Loss: 0.7136686444282532\n",
            "Batch: 759, Loss: 0.4217544496059418\n",
            "Batch: 760, Loss: 0.4847157299518585\n",
            "Batch: 761, Loss: 0.630279004573822\n",
            "Batch: 762, Loss: 0.591782808303833\n",
            "Batch: 763, Loss: 0.5842998623847961\n",
            "Batch: 764, Loss: 0.6085186004638672\n",
            "Batch: 765, Loss: 0.6889694929122925\n",
            "Batch: 766, Loss: 0.8334798812866211\n",
            "Batch: 767, Loss: 0.6385462880134583\n",
            "Batch: 768, Loss: 0.7174454927444458\n",
            "Batch: 769, Loss: 0.5114924907684326\n",
            "Batch: 770, Loss: 0.5146018862724304\n",
            "Batch: 771, Loss: 0.7465205192565918\n",
            "Batch: 772, Loss: 0.6496559381484985\n",
            "Batch: 773, Loss: 0.6237215995788574\n",
            "Batch: 774, Loss: 0.6969224810600281\n",
            "Batch: 775, Loss: 0.5976212620735168\n",
            "Batch: 776, Loss: 0.6702812910079956\n",
            "Batch: 777, Loss: 0.8393077254295349\n",
            "Batch: 778, Loss: 0.5727975964546204\n",
            "Batch: 779, Loss: 0.5851538181304932\n",
            "Batch: 780, Loss: 0.5914365649223328\n",
            "Batch: 781, Loss: 0.6040166616439819\n",
            "Batch: 782, Loss: 0.5973733067512512\n",
            "Batch: 783, Loss: 0.543383777141571\n",
            "Batch: 784, Loss: 0.6109495759010315\n",
            "Batch: 785, Loss: 0.8485401272773743\n",
            "Batch: 786, Loss: 0.6460675001144409\n",
            "Batch: 787, Loss: 0.6566422581672668\n",
            "Batch: 788, Loss: 0.5098817348480225\n",
            "Batch: 789, Loss: 0.491036981344223\n",
            "Batch: 790, Loss: 0.6406443119049072\n",
            "Batch: 791, Loss: 0.7735382318496704\n",
            "Batch: 792, Loss: 0.7026079297065735\n",
            "Batch: 793, Loss: 0.6989493370056152\n",
            "Batch: 794, Loss: 0.6296380758285522\n",
            "Batch: 795, Loss: 0.6231385469436646\n",
            "Batch: 796, Loss: 0.5260425209999084\n",
            "Batch: 797, Loss: 0.7565865516662598\n",
            "Batch: 798, Loss: 0.7019398808479309\n",
            "Batch: 799, Loss: 0.6373399496078491\n",
            "Batch: 800, Loss: 0.5410400032997131\n",
            "Batch: 801, Loss: 0.8219148516654968\n",
            "Batch: 802, Loss: 0.591456949710846\n",
            "Batch: 803, Loss: 0.6075118780136108\n",
            "Batch: 804, Loss: 0.6380148530006409\n",
            "Batch: 805, Loss: 0.6760455369949341\n",
            "Batch: 806, Loss: 0.5678837895393372\n",
            "Batch: 807, Loss: 0.6457023024559021\n",
            "Batch: 808, Loss: 0.6024953722953796\n",
            "Batch: 809, Loss: 0.5117679834365845\n",
            "Batch: 810, Loss: 0.6584800481796265\n",
            "Batch: 811, Loss: 0.596605122089386\n",
            "Batch: 812, Loss: 0.7262107729911804\n",
            "Batch: 813, Loss: 0.562012791633606\n",
            "Batch: 814, Loss: 0.9101145267486572\n",
            "Batch: 815, Loss: 0.7536839842796326\n",
            "Batch: 816, Loss: 0.592294454574585\n",
            "Batch: 817, Loss: 0.7709909677505493\n",
            "Batch: 818, Loss: 0.47825804352760315\n",
            "Batch: 819, Loss: 0.6542986631393433\n",
            "Batch: 820, Loss: 0.4775928556919098\n",
            "Batch: 821, Loss: 0.6218933463096619\n",
            "Batch: 822, Loss: 0.7646204233169556\n",
            "Batch: 823, Loss: 0.5709633827209473\n",
            "Batch: 824, Loss: 0.6634500622749329\n",
            "Batch: 825, Loss: 0.5629825592041016\n",
            "Batch: 826, Loss: 0.5487207770347595\n",
            "Batch: 827, Loss: 0.7177116870880127\n",
            "Batch: 828, Loss: 0.603378415107727\n",
            "Batch: 829, Loss: 0.5457662343978882\n",
            "Batch: 830, Loss: 0.6288998126983643\n",
            "Batch: 831, Loss: 0.807184100151062\n",
            "Batch: 832, Loss: 0.5614115595817566\n",
            "Batch: 833, Loss: 0.729252815246582\n",
            "Batch: 834, Loss: 0.6549291014671326\n",
            "Batch: 835, Loss: 0.7051753997802734\n",
            "Batch: 836, Loss: 0.5347440242767334\n",
            "Batch: 837, Loss: 0.8283076882362366\n",
            "Batch: 838, Loss: 0.5244532823562622\n",
            "Batch: 839, Loss: 0.7236166596412659\n",
            "Batch: 840, Loss: 0.5899220108985901\n",
            "Batch: 841, Loss: 0.6335192322731018\n",
            "Batch: 842, Loss: 0.812034010887146\n",
            "Batch: 843, Loss: 0.7817937135696411\n",
            "Batch: 844, Loss: 0.5470207333564758\n",
            "Batch: 845, Loss: 0.5416996479034424\n",
            "Batch: 846, Loss: 0.4481993317604065\n",
            "Batch: 847, Loss: 0.5733529925346375\n",
            "Batch: 848, Loss: 0.5561549067497253\n",
            "Batch: 849, Loss: 0.4601844251155853\n",
            "Batch: 850, Loss: 0.4571807086467743\n",
            "Batch: 851, Loss: 0.6381652355194092\n",
            "Batch: 852, Loss: 0.5779464244842529\n",
            "Batch: 853, Loss: 0.639512300491333\n",
            "Batch: 854, Loss: 0.57830411195755\n",
            "Batch: 855, Loss: 0.539984405040741\n",
            "Batch: 856, Loss: 0.6445208787918091\n",
            "Batch: 857, Loss: 0.774528443813324\n",
            "Batch: 858, Loss: 0.5757173299789429\n",
            "Batch: 859, Loss: 0.7395725250244141\n",
            "Batch: 860, Loss: 0.5012239217758179\n",
            "Batch: 861, Loss: 0.5731905102729797\n",
            "Batch: 862, Loss: 0.6356980204582214\n",
            "Batch: 863, Loss: 0.5058585405349731\n",
            "Batch: 864, Loss: 0.6225601434707642\n",
            "Batch: 865, Loss: 0.8107091784477234\n",
            "Batch: 866, Loss: 0.6923058032989502\n",
            "Batch: 867, Loss: 0.5550732612609863\n",
            "Batch: 868, Loss: 0.7650358080863953\n",
            "Batch: 869, Loss: 0.6526920199394226\n",
            "Batch: 870, Loss: 0.736343264579773\n",
            "Batch: 871, Loss: 0.5924171209335327\n",
            "Batch: 872, Loss: 0.5597836971282959\n",
            "Batch: 873, Loss: 0.7949168086051941\n",
            "Batch: 874, Loss: 0.5404436588287354\n",
            "Batch: 875, Loss: 0.6510735750198364\n",
            "Batch: 876, Loss: 0.5778485536575317\n",
            "Batch: 877, Loss: 0.5095645189285278\n",
            "Batch: 878, Loss: 0.7589080929756165\n",
            "Batch: 879, Loss: 0.7202188968658447\n",
            "Batch: 880, Loss: 0.6313079595565796\n",
            "Batch: 881, Loss: 0.6881155371665955\n",
            "Batch: 882, Loss: 0.7236010432243347\n",
            "Batch: 883, Loss: 0.5517274141311646\n",
            "Batch: 884, Loss: 0.40510863065719604\n",
            "Batch: 885, Loss: 0.6411073803901672\n",
            "Batch: 886, Loss: 0.4034480154514313\n",
            "Batch: 887, Loss: 0.7129675149917603\n",
            "Batch: 888, Loss: 0.5143674612045288\n",
            "Batch: 889, Loss: 0.5083722472190857\n",
            "Batch: 890, Loss: 0.45425736904144287\n",
            "Batch: 891, Loss: 0.6496536731719971\n",
            "Batch: 892, Loss: 0.7081182599067688\n",
            "Batch: 893, Loss: 0.6832846999168396\n",
            "Batch: 894, Loss: 0.5432384610176086\n",
            "Batch: 895, Loss: 0.6884261965751648\n",
            "Batch: 896, Loss: 0.6121780276298523\n",
            "Batch: 897, Loss: 0.43889814615249634\n",
            "Batch: 898, Loss: 0.8522420525550842\n",
            "Batch: 899, Loss: 0.49301159381866455\n",
            "Batch: 900, Loss: 0.7273231744766235\n",
            "Batch: 901, Loss: 0.6783976554870605\n",
            "Batch: 902, Loss: 0.7158721685409546\n",
            "Batch: 903, Loss: 0.676915168762207\n",
            "Batch: 904, Loss: 0.7095970511436462\n",
            "Batch: 905, Loss: 0.6534756422042847\n",
            "Batch: 906, Loss: 0.5897827744483948\n",
            "Batch: 907, Loss: 0.6723396182060242\n",
            "Batch: 908, Loss: 0.6193965673446655\n",
            "Batch: 909, Loss: 0.6186730861663818\n",
            "Batch: 910, Loss: 0.5079957842826843\n",
            "Batch: 911, Loss: 0.6109662652015686\n",
            "Batch: 912, Loss: 0.6447784304618835\n",
            "Batch: 913, Loss: 0.6352670788764954\n",
            "Batch: 914, Loss: 0.7240836024284363\n",
            "Batch: 915, Loss: 0.741016149520874\n",
            "Batch: 916, Loss: 0.5891452431678772\n",
            "Batch: 917, Loss: 0.6541051268577576\n",
            "Batch: 918, Loss: 0.4578317403793335\n",
            "Batch: 919, Loss: 0.775843620300293\n",
            "Batch: 920, Loss: 0.5031096935272217\n",
            "Batch: 921, Loss: 0.6730491518974304\n",
            "Batch: 922, Loss: 0.5100734233856201\n",
            "Batch: 923, Loss: 0.744724452495575\n",
            "Batch: 924, Loss: 0.5182812213897705\n",
            "Batch: 925, Loss: 0.5732871890068054\n",
            "Batch: 926, Loss: 0.588035523891449\n",
            "Batch: 927, Loss: 0.6937894225120544\n",
            "Batch: 928, Loss: 0.4773441553115845\n",
            "Batch: 929, Loss: 0.5381672978401184\n",
            "Batch: 930, Loss: 0.6132909655570984\n",
            "Batch: 931, Loss: 0.5435023307800293\n",
            "Batch: 932, Loss: 0.7875753045082092\n",
            "Batch: 933, Loss: 0.5156441926956177\n",
            "Batch: 934, Loss: 0.6731938123703003\n",
            "Batch: 935, Loss: 0.5816032290458679\n",
            "Batch: 936, Loss: 0.5270612835884094\n",
            "Batch: 937, Loss: 0.5809073448181152\n",
            "Batch: 938, Loss: 0.6932792067527771\n",
            "Training loss: 1.0027145984838766\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}